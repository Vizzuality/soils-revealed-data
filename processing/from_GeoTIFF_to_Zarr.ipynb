{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert `GeoTIFFs` in Google Cloud Storage to `Zarr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dask.array as da\n",
    "import zarr\n",
    "import rioxarray\n",
    "import gcsfs\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from pathlib import Path \n",
    "env_path = Path('.') / '.env'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From `GeoTIFFs` to `Zarr`\n",
    "\n",
    "We use the [xarray](http://xarray.pydata.org/en/stable/io.html#reading-and-writing-files) library to convert `GeoTIFFs` into `Zarr`. \n",
    "\n",
    "GeoTIFFs can be opened using [rasterio](http://xarray.pydata.org/en/stable/io.html#rasterio) with this xarray method: `xarray.open_rasterio`. Additionally, you can use [rioxarray](https://corteva.github.io/rioxarray/stable/) for reading GeoTiffs.\n",
    "\n",
    "To save `xarray.Datasets` as a `Zarr` we can us the [Xarrayâ€™s Zarr backend](http://xarray.pydata.org/en/stable/io.html#zarr). [Zarr](http://zarr.readthedocs.io/) is a Python package providing an implementation of chunked, compressed, N-dimensional arrays. Zarr has the ability to read and write xarray datasets directly from / to cloud storage buckets such as Amazon S3 and Google Cloud Storage.\n",
    "\n",
    "Xarray needs to read all of the zarr metadata when it opens a dataset. With version 2.3, Zarr will support a feature called consolidated metadata, which allows all metadata for the entire dataset to be stored with a single key (by default called `.zmetadata`). This can drastically speed up opening the store. To write consolidated metadata, pass the `consolidated=True` option to the `Dataset.to_zarr` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Create `xarray.Dataset` in memory\n",
    "\n",
    "### Argentina SOC stocks dataset\n",
    "\n",
    "**Data location:**\n",
    "\n",
    "https://storage.cloud.google.com/vizz-data-transfer/SOC_maps/\n",
    "\n",
    "**Data description:**\n",
    "\n",
    "The name structure of the files is `Feb19_cstocks_YEAR_030_ll.tif`:\n",
    "- YEAR: 1982-2017\n",
    "- The stocks were calculated in the 0 to 30 cm interval. \n",
    "\n",
    "**Output data location:**\n",
    " \n",
    "https://storage.cloud.google.com/vizz-data-transfer/SOC_maps/soil-tnc-data.zarr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the `xarray.Dataset`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://storage.googleapis.com/vizz-data-transfer/SOC_maps/SOC_stock/'\n",
    "ds_name = 'stocks'\n",
    "depth = ['0-30']\n",
    "times = pd.date_range(\"1982\", \"2018\", freq='A-DEC', name=\"time\")\n",
    "years = np.arange(1982, 2018, 1).astype(np.str)\n",
    "\n",
    "for n, year in enumerate(years):\n",
    "    print(f'Year: {year}')\n",
    "    url = base_url + 'Feb19_cstocks_' + year + '_030_ll.tif'\n",
    "    \n",
    "    xda = xr.open_rasterio(url).squeeze().drop(\"band\")\n",
    "    \n",
    "    # replace all values equal to -9999 with np.nan\n",
    "    xda = xda.where(xda != -9999.) \n",
    "    \n",
    "    # add time and depth coordinates\n",
    "    xda = xda.assign_coords({\"depth\": depth[0], \"time\": times[n]}).expand_dims(['depht', 'time'])\n",
    "    \n",
    "    # convert to Dataset\n",
    "    if n == 0:\n",
    "        xds = xr.Dataset({ds_name: xda}, attrs=xda.attrs)\n",
    "    else:\n",
    "        xds = xr.concat([xds, xr.Dataset({ds_name: xda}, attrs=xda.attrs)], dim='time')\n",
    "        \n",
    "    # select sub-area\n",
    "    #xds = xds.isel(x=slice(2000, 2100), y=slice(4000, 4100))\n",
    "xds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save `xarray.Dataset` as `Zarr` in Google Cloud Storage bucket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'soc-platform'\n",
    "bucket_name = 'vizz-data-transfer'\n",
    "root = bucket_name+'/SOC_maps/soil-data.zarr'\n",
    "group = 'experimental-dataset-stock'\n",
    "private_key = json.loads(os.getenv(\"PRIVATE_KEY\"))\n",
    "#base_url = 'https://storage.googleapis.com/vizz-data-transfer/SOC_maps/SOC_stock/'\n",
    "gc = gcsfs.GCSFileSystem(project=project_name, token=private_key)\n",
    "\n",
    "# Save in GCS\n",
    "store = gc.get_mapper(root, check=False, create=True)\n",
    "xds.to_zarr(store=store, group=group, mode='w', consolidated=True)\n",
    "# consolidate metadata at root\n",
    "zarr.consolidate_metadata(store)\n",
    "c = gc.exists(f\"{root}/.zmetadata\")\n",
    "print(f\"{root} is consoldiated? {c}\")\n",
    "with zarr.open(store, mode='r') as z:\n",
    "    print(z.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argentina SOC concentration dataset\n",
    "\n",
    "**Input data location:**\n",
    "\n",
    "https://storage.cloud.google.com/vizz-data-transfer/SOC_maps/\n",
    "\n",
    "**Data description:**\n",
    "\n",
    "The name structure of the files is `SOC_YEAR_qQUANTILE_dDEPTH.tif`:\n",
    "\n",
    "- YEAR: 1982-2017\n",
    "- QUANTILE: 0.05,0.5,0.95 percentiles\n",
    "- DEPTH:\n",
    "    - 2.5 --> for the interval 0-5cm\n",
    "    - 10 --> for the interval 5-15cm\n",
    "    - 22.5 --> for the interval 15-30cm\n",
    "    - 45 --> for the interval 30-60cm\n",
    "    - 80 --> for the interval 60-100cm\n",
    "    - 150 --> for the interval 100-200cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://storage.googleapis.com/vizz-data-transfer/SOC_maps/SOC_concentration/'\n",
    "ds_name = 'concentration'\n",
    "times = pd.date_range(\"1982\", \"2018\", freq='A-DEC', name=\"time\")\n",
    "depths = {'0-5': '2.5', '5-15': '10', '15-30': '22.5', '30-60': '45', '60-100': '80', '100-200': '150'}\n",
    "years = np.arange(1982, 1984, 1).astype(np.str)\n",
    "\n",
    "for n, year in enumerate(years):\n",
    "    for depth,dname in depths.items():\n",
    "        print(f'Year: {year}')\n",
    "        print(f'Depth: {depth}')\n",
    "        url = base_url + 'SOC_' + year + '_q0.5_d'+ dname + '.tif'\n",
    "        \n",
    "        xda = xr.open_rasterio(url).squeeze().drop(\"band\")\n",
    "        \n",
    "        # replace all values equal to 0 with np.nan\n",
    "        xda = xda.where(xda != 0) \n",
    "\n",
    "        # add time and depth coordinates\n",
    "        xda = xda.assign_coords({\"depth\": depth, \"time\": times[n]}).expand_dims(['depht', 'time'])\n",
    "        \n",
    "        # convert to Dataset and concatenate by depht\n",
    "        if depth == '0-5':\n",
    "            xds_depth = xr.Dataset({ds_name: xda}, attrs=xda.attrs)\n",
    "        else:\n",
    "            xds_depth = xr.concat([xds_depth, xr.Dataset({ds_name: xda}, attrs=xda.attrs)], dim='depht')\n",
    "            \n",
    "    # select sub-area\n",
    "    xds_depth = xds_depth.isel(x=slice(2000, 2100), y=slice(4000, 4100))\n",
    "        \n",
    "    # concatenate Datasets by time\n",
    "    if n == 0:\n",
    "        xds = xds_depth\n",
    "    else:\n",
    "        xds = xr.concat([xds, xds_depth], dim='time')\n",
    "        \n",
    "xds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save `xarray.Dataset` as `Zarr` in Google Cloud Storage bucket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = '../data/soil-data.zarr'\n",
    "project_name = 'soc-platform'\n",
    "bucket_name = 'vizz-data-transfer'\n",
    "root = bucket_name+'/SOC_maps/soil-data.zarr'\n",
    "group = 'experimental-dataset-concentration'\n",
    "private_key = json.loads(os.getenv(\"PRIVATE_KEY\"))\n",
    "base_url = 'https://storage.googleapis.com/vizz-data-transfer/SOC_maps/SOC_stock/'\n",
    "gc = gcsfs.GCSFileSystem(project=project_name, token=private_key)\n",
    "\n",
    "# Save in GCS\n",
    "store = gc.get_mapper(root, check=False, create=True)\n",
    "store = gc.get_mapper(root)\n",
    "xds.to_zarr(store=store, group=group, mode='w', consolidated=True)\n",
    "# consolidate metadata at root\n",
    "zarr.consolidate_metadata(store)\n",
    "c = gc.exists(f\"{root}/.zmetadata\")\n",
    "print(f\"{root} is consoldiated? {c}\")\n",
    "with zarr.open(store, mode='r') as z:\n",
    "    print(z.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read `xarray.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to GS\n",
    "project_name = 'soc-platform'\n",
    "bucket_name = 'vizz-data-transfer'\n",
    "root = bucket_name+'/SOC_maps/soil-data.zarr'\n",
    "group = 'experimental-dataset-stock'\n",
    "private_key = json.loads(os.getenv(\"PRIVATE_KEY\"))\n",
    "\n",
    "gc = gcsfs.GCSFileSystem(project=project_name, token=private_key)\n",
    "store = gc.get_mapper(root)\n",
    "# Check zarr is consolidated\n",
    "#consolidated = gc.exists(f'{root}/.zmetadata')\n",
    "# Cache the zarr store\n",
    "#cache = zarr.LRUStoreCache(store, max_size=None)\n",
    "# Return cached zarr group\n",
    "ds_gcs = xr.open_zarr(store=store, group=group, consolidated=True)\n",
    "ds_gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ds_gcs.stocks.values[0,1,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Create `xarray.Dataset` on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "local_path = '../data/soil-data.zarr'\n",
    "project_name = 'soc-platform'\n",
    "bucket_name = 'vizz-data-transfer'\n",
    "root = bucket_name+'/SOC_maps/soil-data.zarr'\n",
    "group = 'experimental-dataset-stock'\n",
    "private_key = json.loads(os.getenv(\"PRIVATE_KEY\"))\n",
    "ds_name = 'stocks'\n",
    "base_url = 'https://storage.googleapis.com/vizz-data-transfer/SOC_maps/SOC_stock/'\n",
    "gc = gcsfs.GCSFileSystem(project=project_name, token=private_key)\n",
    "\n",
    "times = pd.date_range(\"1982\", \"2018\", freq='A-DEC', name=\"time\")\n",
    "depth = ['0-30']\n",
    "years = np.arange(1982, 1985, 1).astype(np.str)\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    print(f'Year: {year}')\n",
    "    url = base_url + 'Feb19_cstocks_' + year + '_030_ll.tif'\n",
    "    xda = xr.open_rasterio(url).squeeze().drop(\"band\")\n",
    "    \n",
    "    # replace all values equal to -9999 with np.nan\n",
    "    xda = xda.where(xda != -9999.) \n",
    "    \n",
    "    # add time and depth coordinates\n",
    "    xda = xda.assign_coords({\"depth\": depth[0], \"time\": times[i]}).expand_dims(['depht', 'time'])\n",
    "    \n",
    "    # convert to Dataset\n",
    "    xds = xr.Dataset({ds_name: xda}, attrs=xda.attrs)\n",
    "    \n",
    "    # select sub-area\n",
    "    #xds = xds.isel(x=slice(2000, 2100), y=slice(4000, 4100))\n",
    "    \n",
    "    # save zarr into Google Cloud Storage bucket\n",
    "    if i == 0:\n",
    "        # Save in GCS\n",
    "        #store = gc.get_mapper(root, check=False, create=True)\n",
    "        #store = gc.get_mapper(root)\n",
    "        #xds.to_zarr(store=store, group=group, mode='w', consolidated=True)\n",
    "        # consolidate metadata at root\n",
    "        #zarr.consolidate_metadata(store)\n",
    "        #c = gc.exists(f\"{root}/.zmetadata\")\n",
    "        #print(f\"{root} is consoldiated? {c}\")\n",
    "        #with zarr.open(store, mode='r') as z:\n",
    "        #    print(z.tree())\n",
    "        \n",
    "        # Save locally\n",
    "        xds.to_zarr(local_path, group=group, mode='w', consolidated=True)\n",
    "        # consolidate metadata at root\n",
    "        zarr.consolidate_metadata(local_path)\n",
    "        with zarr.open(local_path, mode='r') as z:\n",
    "            print(z.tree())\n",
    "    else:\n",
    "        # Save in GCS\n",
    "        #store = gc.get_mapper(root, check=True, create=False)\n",
    "        #xds.to_zarr(store=store, group=group, mode='a', append_dim='time', consolidated=True)\n",
    "        # consolidate metadata at root\n",
    "        #zarr.consolidate_metadata(store)\n",
    "        #c = gc.exists(f\"{root}/.zmetadata\")\n",
    "        #print(f\"{root} is consoldiated? {c}\")\n",
    "        #with zarr.open(store, mode='r') as z:\n",
    "        #    print(z.tree())\n",
    "        \n",
    "        # Save locally\n",
    "        xds.to_zarr(local_path, group=group, append_dim='time', consolidated=True)\n",
    "        # consolidate metadata at root\n",
    "        zarr.consolidate_metadata(local_path)\n",
    "        with zarr.open(local_path, mode='r') as z:\n",
    "            print(z.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read `xarray.Dataset`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = '../data/soil-data.zarr'\n",
    "group = 'experimental-dataset'\n",
    "ds_zarr = xr.open_zarr(local_path, group=group)\n",
    "ds_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to GS\n",
    "project_name = 'soc-platform'\n",
    "bucket_name = 'vizz-data-transfer'\n",
    "root = bucket_name+'/SOC_maps/soil-data.zarr'\n",
    "group = 'experimental-dataset'\n",
    "private_key = json.loads(os.getenv(\"PRIVATE_KEY\"))\n",
    "\n",
    "gc = gcsfs.GCSFileSystem(project=project_name, token=private_key)\n",
    "store = gc.get_mapper(root)\n",
    "# Check zarr is consolidated\n",
    "#consolidated = gc.exists(f'{root}/.zmetadata')\n",
    "# Cache the zarr store\n",
    "#cache = zarr.LRUStoreCache(store, max_size=None)\n",
    "# Return cached zarr group\n",
    "ds_gcs = xr.open_zarr(store=store, group=group, consolidated=True)\n",
    "ds_gcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[to_zarr append with gcsmap does not work properly #3251](https://github.com/pydata/xarray/issues/3251)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
